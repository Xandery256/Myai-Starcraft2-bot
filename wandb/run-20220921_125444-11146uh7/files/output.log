On iteration:  0
RESETTING ENVIRONMENT
Logging to logs/test_run/PPO_0
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 6.65e+03 |
|    ep_rew_mean     | -263     |
| time/              |          |
|    fps             | 12       |
|    iterations      | 1        |
|    time_elapsed    | 158      |
|    total_timesteps | 53248    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 6.65e+03    |
|    ep_rew_mean          | -263        |
| time/                   |             |
|    fps                  | 8           |
|    iterations           | 2           |
|    time_elapsed         | 490         |
|    total_timesteps      | 55296       |
| train/                  |             |
|    approx_kl            | 0.083671466 |
|    clip_fraction        | 0.476       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.36       |
|    explained_variance   | 0.926       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0657     |
|    n_updates            | 260         |
|    policy_gradient_loss | -0.0597     |
|    value_loss           | 0.543       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 6.65e+03   |
|    ep_rew_mean          | -263       |
| time/                   |            |
|    fps                  | 8          |
|    iterations           | 3          |
|    time_elapsed         | 721        |
|    total_timesteps      | 57344      |
| train/                  |            |
|    approx_kl            | 0.08786357 |
|    clip_fraction        | 0.452      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.18      |
|    explained_variance   | 0.0324     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0765    |
|    n_updates            | 270        |
|    policy_gradient_loss | -0.0506    |
|    value_loss           | 0.8        |
----------------------------------------
RESETTING ENVIRONMENT
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 6.63e+03   |
|    ep_rew_mean          | -261       |
| time/                   |            |
|    fps                  | 8          |
|    iterations           | 4          |
|    time_elapsed         | 929        |
|    total_timesteps      | 59392      |
| train/                  |            |
|    approx_kl            | 0.11131422 |
|    clip_fraction        | 0.51       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.25      |
|    explained_variance   | 0.589      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0851    |
|    n_updates            | 280        |
|    policy_gradient_loss | -0.0631    |
|    value_loss           | 0.329      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 6.63e+03    |
|    ep_rew_mean          | -261        |
| time/                   |             |
|    fps                  | 8           |
|    iterations           | 5           |
|    time_elapsed         | 1196        |
|    total_timesteps      | 61440       |
| train/                  |             |
|    approx_kl            | 0.029753204 |
|    clip_fraction        | 0.257       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.41       |
|    explained_variance   | 0.00747     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0132      |
|    n_updates            | 290         |
|    policy_gradient_loss | -0.0194     |
|    value_loss           | 740         |
-----------------------------------------
On iteration:  1
Logging to logs/test_run/PPO_0
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 6.63e+03 |
|    ep_rew_mean     | -261     |
| time/              |          |
|    fps             | 8        |
|    iterations      | 1        |
|    time_elapsed    | 246      |
|    total_timesteps | 63488    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 6.63e+03   |
|    ep_rew_mean          | -261       |
| time/                   |            |
|    fps                  | 7          |
|    iterations           | 2          |
|    time_elapsed         | 515        |
|    total_timesteps      | 65536      |
| train/                  |            |
|    approx_kl            | 0.12435408 |
|    clip_fraction        | 0.492      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.2       |
|    explained_variance   | 0.0135     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0963    |
|    n_updates            | 310        |
|    policy_gradient_loss | -0.0741    |
|    value_loss           | 0.421      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 6.63e+03   |
|    ep_rew_mean          | -261       |
| time/                   |            |
|    fps                  | 7          |
|    iterations           | 3          |
|    time_elapsed         | 776        |
|    total_timesteps      | 67584      |
| train/                  |            |
|    approx_kl            | 0.10511078 |
|    clip_fraction        | 0.524      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.42      |
|    explained_variance   | 0.613      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0404    |
|    n_updates            | 320        |
|    policy_gradient_loss | -0.0522    |
|    value_loss           | 0.751      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 6.63e+03   |
|    ep_rew_mean          | -261       |
| time/                   |            |
|    fps                  | 8          |
|    iterations           | 4          |
|    time_elapsed         | 1021       |
|    total_timesteps      | 69632      |
| train/                  |            |
|    approx_kl            | 0.04676464 |
|    clip_fraction        | 0.326      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.49      |
|    explained_variance   | 0.381      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.165      |
|    n_updates            | 330        |
|    policy_gradient_loss | -0.047     |
|    value_loss           | 1.36       |
----------------------------------------
RESETTING ENVIRONMENT
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 8.05e+03   |
|    ep_rew_mean          | -130       |
| time/                   |            |
|    fps                  | 8          |
|    iterations           | 5          |
|    time_elapsed         | 1229       |
|    total_timesteps      | 71680      |
| train/                  |            |
|    approx_kl            | 0.07562958 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.47      |
|    explained_variance   | 0.237      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.045     |
|    n_updates            | 340        |
|    policy_gradient_loss | -0.0587    |
|    value_loss           | 0.769      |
----------------------------------------
On iteration:  2
Logging to logs/test_run/PPO_0
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 8.05e+03 |
|    ep_rew_mean     | -130     |
| time/              |          |
|    fps             | 18       |
|    iterations      | 1        |
|    time_elapsed    | 109      |
|    total_timesteps | 73728    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 8.05e+03   |
|    ep_rew_mean          | -130       |
| time/                   |            |
|    fps                  | 10         |
|    iterations           | 2          |
|    time_elapsed         | 395        |
|    total_timesteps      | 75776      |
| train/                  |            |
|    approx_kl            | 0.06261834 |
|    clip_fraction        | 0.438      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.28      |
|    explained_variance   | 0.939      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0948    |
|    n_updates            | 360        |
|    policy_gradient_loss | -0.0663    |
|    value_loss           | 0.129      |
----------------------------------------
RESETTING ENVIRONMENT
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 7.64e+03   |
|    ep_rew_mean          | -168       |
| time/                   |            |
|    fps                  | 9          |
|    iterations           | 3          |
|    time_elapsed         | 630        |
|    total_timesteps      | 77824      |
| train/                  |            |
|    approx_kl            | 0.07089484 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.2       |
|    explained_variance   | 0.296      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0642    |
|    n_updates            | 370        |
|    policy_gradient_loss | -0.0466    |
|    value_loss           | 0.418      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 7.64e+03    |
|    ep_rew_mean          | -168        |
| time/                   |             |
|    fps                  | 9           |
|    iterations           | 4           |
|    time_elapsed         | 862         |
|    total_timesteps      | 79872       |
| train/                  |             |
|    approx_kl            | 0.040168718 |
|    clip_fraction        | 0.221       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.32       |
|    explained_variance   | 0.308       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.103       |
|    n_updates            | 380         |
|    policy_gradient_loss | -0.0223     |
|    value_loss           | 722         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 7.64e+03    |
|    ep_rew_mean          | -168        |
| time/                   |             |
|    fps                  | 8           |
|    iterations           | 5           |
|    time_elapsed         | 1172        |
|    total_timesteps      | 81920       |
| train/                  |             |
|    approx_kl            | 0.076600164 |
|    clip_fraction        | 0.418       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.32       |
|    explained_variance   | 0.642       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0778     |
|    n_updates            | 390         |
|    policy_gradient_loss | -0.0619     |
|    value_loss           | 0.201       |
-----------------------------------------
On iteration:  3
Logging to logs/test_run/PPO_0
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 7.64e+03 |
|    ep_rew_mean     | -168     |
| time/              |          |
|    fps             | 9        |
|    iterations      | 1        |
|    time_elapsed    | 214      |
|    total_timesteps | 83968    |
---------------------------------
RESETTING ENVIRONMENT
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 7.81e+03    |
|    ep_rew_mean          | -150        |
| time/                   |             |
|    fps                  | 9           |
|    iterations           | 2           |
|    time_elapsed         | 454         |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 0.034947842 |
|    clip_fraction        | 0.288       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.33       |
|    explained_variance   | 0.58        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.371       |
|    n_updates            | 410         |
|    policy_gradient_loss | -0.0592     |
|    value_loss           | 2.27        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 7.81e+03   |
|    ep_rew_mean          | -150       |
| time/                   |            |
|    fps                  | 9          |
|    iterations           | 3          |
|    time_elapsed         | 655        |
|    total_timesteps      | 88064      |
| train/                  |            |
|    approx_kl            | 0.07057273 |
|    clip_fraction        | 0.323      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.16      |
|    explained_variance   | 0.461      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00517   |
|    n_updates            | 420        |
|    policy_gradient_loss | -0.0257    |
|    value_loss           | 719        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 7.81e+03   |
|    ep_rew_mean          | -150       |
| time/                   |            |
|    fps                  | 8          |
|    iterations           | 4          |
|    time_elapsed         | 924        |
|    total_timesteps      | 90112      |
| train/                  |            |
|    approx_kl            | 0.18180618 |
|    clip_fraction        | 0.601      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | 0.401      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.112     |
|    n_updates            | 430        |
|    policy_gradient_loss | -0.0688    |
|    value_loss           | 0.0272     |
----------------------------------------
RESETTING ENVIRONMENT
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 7.58e+03   |
|    ep_rew_mean          | -180       |
| time/                   |            |
|    fps                  | 8          |
|    iterations           | 5          |
|    time_elapsed         | 1141       |
|    total_timesteps      | 92160      |
| train/                  |            |
|    approx_kl            | 0.19538766 |
|    clip_fraction        | 0.549      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.13      |
|    explained_variance   | 0.296      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0935    |
|    n_updates            | 440        |
|    policy_gradient_loss | -0.0648    |
|    value_loss           | 0.311      |
----------------------------------------
On iteration:  4
Logging to logs/test_run/PPO_0
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 7.58e+03 |
|    ep_rew_mean     | -180     |
| time/              |          |
|    fps             | 13       |
|    iterations      | 1        |
|    time_elapsed    | 155      |
|    total_timesteps | 94208    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 7.58e+03   |
|    ep_rew_mean          | -180       |
| time/                   |            |
|    fps                  | 8          |
|    iterations           | 2          |
|    time_elapsed         | 491        |
|    total_timesteps      | 96256      |
| train/                  |            |
|    approx_kl            | 0.08426137 |
|    clip_fraction        | 0.505      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.35      |
|    explained_variance   | 0.707      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0914    |
|    n_updates            | 460        |
|    policy_gradient_loss | -0.0731    |
|    value_loss           | 0.213      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 7.58e+03    |
|    ep_rew_mean          | -180        |
| time/                   |             |
|    fps                  | 7           |
|    iterations           | 3           |
|    time_elapsed         | 780         |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.062321834 |
|    clip_fraction        | 0.319       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.22       |
|    explained_variance   | 0.314       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0692     |
|    n_updates            | 470         |
|    policy_gradient_loss | -0.0621     |
|    value_loss           | 1.67        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 7.58e+03   |
|    ep_rew_mean          | -180       |
| time/                   |            |
|    fps                  | 7          |
|    iterations           | 4          |
|    time_elapsed         | 1077       |
|    total_timesteps      | 100352     |
| train/                  |            |
|    approx_kl            | 0.05664538 |
|    clip_fraction        | 0.321      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.05      |
|    explained_variance   | 0.657      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0472     |
|    n_updates            | 480        |
|    policy_gradient_loss | -0.058     |
|    value_loss           | 2.34       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 7.58e+03    |
|    ep_rew_mean          | -180        |
| time/                   |             |
|    fps                  | 7           |
|    iterations           | 5           |
|    time_elapsed         | 1391        |
|    total_timesteps      | 102400      |
| train/                  |             |
|    approx_kl            | 0.017069029 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.27       |
|    explained_variance   | 0.224       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.22        |
|    n_updates            | 490         |
|    policy_gradient_loss | -0.0368     |
|    value_loss           | 9.65        |
-----------------------------------------
On iteration:  5
Logging to logs/test_run/PPO_0
RESETTING ENVIRONMENT
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 7.94e+03 |
|    ep_rew_mean     | -66.5    |
| time/              |          |
|    fps             | 13       |
|    iterations      | 1        |
|    time_elapsed    | 151      |
|    total_timesteps | 104448   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 7.94e+03   |
|    ep_rew_mean          | -66.5      |
| time/                   |            |
|    fps                  | 8          |
|    iterations           | 2          |
|    time_elapsed         | 502        |
|    total_timesteps      | 106496     |
| train/                  |            |
|    approx_kl            | 0.04561251 |
|    clip_fraction        | 0.273      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.09      |
|    explained_variance   | 0.541      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0119    |
|    n_updates            | 510        |
|    policy_gradient_loss | -0.021     |
|    value_loss           | 653        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 7.94e+03   |
|    ep_rew_mean          | -66.5      |
| time/                   |            |
|    fps                  | 7          |
|    iterations           | 3          |
|    time_elapsed         | 863        |
|    total_timesteps      | 108544     |
| train/                  |            |
|    approx_kl            | 0.16772068 |
|    clip_fraction        | 0.534      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.15      |
|    explained_variance   | 0.458      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0562    |
|    n_updates            | 520        |
|    policy_gradient_loss | -0.0537    |
|    value_loss           | 0.331      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 7.94e+03    |
|    ep_rew_mean          | -66.5       |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 4           |
|    time_elapsed         | 1194        |
|    total_timesteps      | 110592      |
| train/                  |             |
|    approx_kl            | 0.122852355 |
|    clip_fraction        | 0.458       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.22       |
|    explained_variance   | 0.371       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0311     |
|    n_updates            | 530         |
|    policy_gradient_loss | -0.0554     |
|    value_loss           | 1.09        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 7.94e+03   |
|    ep_rew_mean          | -66.5      |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 5          |
|    time_elapsed         | 1526       |
|    total_timesteps      | 112640     |
| train/                  |            |
|    approx_kl            | 0.13617605 |
|    clip_fraction        | 0.479      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.11      |
|    explained_variance   | -0.302     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0527    |
|    n_updates            | 540        |
|    policy_gradient_loss | -0.0681    |
|    value_loss           | 1.76       |
----------------------------------------
On iteration:  6
Logging to logs/test_run/PPO_0
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 7.94e+03 |
|    ep_rew_mean     | -66.5    |
| time/              |          |
|    fps             | 8        |
|    iterations      | 1        |
|    time_elapsed    | 237      |
|    total_timesteps | 114688   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 7.94e+03   |
|    ep_rew_mean          | -66.5      |
| time/                   |            |
|    fps                  | 7          |
|    iterations           | 2          |
|    time_elapsed         | 516        |
|    total_timesteps      | 116736     |
| train/                  |            |
|    approx_kl            | 0.04195957 |
|    clip_fraction        | 0.301      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.05      |
|    explained_variance   | 0.44       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.483      |
|    n_updates            | 560        |
|    policy_gradient_loss | -0.0319    |
|    value_loss           | 5.04       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 7.94e+03    |
|    ep_rew_mean          | -66.5       |
| time/                   |             |
|    fps                  | 7           |
|    iterations           | 3           |
|    time_elapsed         | 805         |
|    total_timesteps      | 118784      |
| train/                  |             |
|    approx_kl            | 0.011691742 |
|    clip_fraction        | 0.116       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.05       |
|    explained_variance   | 0.0511      |
|    learning_rate        | 0.0003      |
|    loss                 | 7.74        |
|    n_updates            | 570         |
|    policy_gradient_loss | -0.0226     |
|    value_loss           | 38.5        |
-----------------------------------------
Traceback (most recent call last):
  File "load-train-model.py", line 44, in <module>
    model.learn(total_timesteps=TIMESTEPS, reset_num_timesteps=False, tb_log_name=f"PPO")
  File "C:\Users\ary93\AppData\Local\Programs\Python\Python38\lib\site-packages\stable_baselines3\ppo\ppo.py", line 310, in learn
    return super().learn(
  File "C:\Users\ary93\AppData\Local\Programs\Python\Python38\lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 267, in learn
    self.train()
  File "C:\Users\ary93\AppData\Local\Programs\Python\Python38\lib\site-packages\stable_baselines3\ppo\ppo.py", line 272, in train
    th.nn.utils.clip_grad_norm_(self.policy.parameters(), self.max_grad_norm)
  File "C:\Users\ary93\AppData\Local\Programs\Python\Python38\lib\site-packages\torch\nn\utils\clip_grad.py", line 42, in clip_grad_norm_
    total_norm = torch.norm(torch.stack([torch.norm(p.grad.detach(), norm_type).to(device) for p in parameters]), norm_type)
  File "C:\Users\ary93\AppData\Local\Programs\Python\Python38\lib\site-packages\torch\nn\utils\clip_grad.py", line 42, in <listcomp>
    total_norm = torch.norm(torch.stack([torch.norm(p.grad.detach(), norm_type).to(device) for p in parameters]), norm_type)
  File "C:\Users\ary93\AppData\Local\Programs\Python\Python38\lib\site-packages\torch\functional.py", line 1451, in norm
    return _VF.norm(input, p, dim=_dim, keepdim=keepdim)  # type: ignore[attr-defined]
KeyboardInterrupt