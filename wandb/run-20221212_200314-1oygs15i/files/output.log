Using cpu device
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
Wrapping the env in a VecTransposeImage.
On iteration:  0
RESETTING ENVIRONMENT
Logging to logs/trainingZerg/PPO_0
Traceback (most recent call last):
  File "C:\Users\ary93\Desktop\BJU Files\Year 4 S1\CpS 499\Myai-Starcraft2-bot\train.py", line 45, in <module>
    model.learn(total_timesteps=TIMESTEPS, reset_num_timesteps=False, tb_log_name=f"PPO")
  File "C:\Python39\lib\site-packages\stable_baselines3\ppo\ppo.py", line 317, in learn
    return super().learn(
  File "C:\Python39\lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 262, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
  File "C:\Python39\lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 181, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
  File "C:\Python39\lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 162, in step
    return self.step_wait()
  File "C:\Python39\lib\site-packages\stable_baselines3\common\vec_env\vec_transpose.py", line 95, in step_wait
    observations, rewards, dones, infos = self.venv.step_wait()
  File "C:\Python39\lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 43, in step_wait
    obs, self.buf_rews[env_idx], self.buf_dones[env_idx], self.buf_infos[env_idx] = self.envs[env_idx].step(
  File "C:\Python39\lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, done, info = self.env.step(action)
  File "C:\Users\ary93\Desktop\BJU Files\Year 4 S1\CpS 499\Myai-Starcraft2-bot\sc2env.py", line 26, in step
    with open('state_rwd_action.pkl', 'rb') as f:
KeyboardInterrupt