Using cpu device
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
Wrapping the env in a VecTransposeImage.
On iteration:  0
RESETTING ENVIRONMENT
Logging to logs/test_run4/PPO_0
-----------------------------
| time/              |      |
|    fps             | 18   |
|    iterations      | 1    |
|    time_elapsed    | 109  |
|    total_timesteps | 2048 |
-----------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 14          |
|    iterations           | 2           |
|    time_elapsed         | 285         |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.016752824 |
|    clip_fraction        | 0.0995      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.3        |
|    explained_variance   | 0.0935      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0626     |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.0288     |
|    value_loss           | 0.00718     |
-----------------------------------------
RESETTING ENVIRONMENT
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 5.52e+03   |
|    ep_rew_mean          | -946       |
| time/                   |            |
|    fps                  | 14         |
|    iterations           | 3          |
|    time_elapsed         | 436        |
|    total_timesteps      | 6144       |
| train/                  |            |
|    approx_kl            | 0.05559099 |
|    clip_fraction        | 0.451      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.26      |
|    explained_variance   | -0.0948    |
|    learning_rate        | 0.0003     |
|    loss                 | -0.114     |
|    n_updates            | 20         |
|    policy_gradient_loss | -0.0818    |
|    value_loss           | 0.0261     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 5.52e+03    |
|    ep_rew_mean          | -946        |
| time/                   |             |
|    fps                  | 14          |
|    iterations           | 4           |
|    time_elapsed         | 548         |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.017583964 |
|    clip_fraction        | 0.13        |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.27       |
|    explained_variance   | 0.000501    |
|    learning_rate        | 0.0003      |
|    loss                 | 137         |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.0156     |
|    value_loss           | 4.05e+03    |
-----------------------------------------
RESETTING ENVIRONMENT
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 4.6e+03    |
|    ep_rew_mean          | -969       |
| time/                   |            |
|    fps                  | 14         |
|    iterations           | 5          |
|    time_elapsed         | 686        |
|    total_timesteps      | 10240      |
| train/                  |            |
|    approx_kl            | 0.05996924 |
|    clip_fraction        | 0.478      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.24      |
|    explained_variance   | 0.841      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.125     |
|    n_updates            | 40         |
|    policy_gradient_loss | -0.0921    |
|    value_loss           | 0.00365    |
----------------------------------------
On iteration:  1
Logging to logs/test_run4/PPO_0
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 4.6e+03  |
|    ep_rew_mean     | -969     |
| time/              |          |
|    fps             | 19       |
|    iterations      | 1        |
|    time_elapsed    | 104      |
|    total_timesteps | 12288    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 4.6e+03    |
|    ep_rew_mean          | -969       |
| time/                   |            |
|    fps                  | 14         |
|    iterations           | 2          |
|    time_elapsed         | 286        |
|    total_timesteps      | 14336      |
| train/                  |            |
|    approx_kl            | 0.07190759 |
|    clip_fraction        | 0.531      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.19      |
|    explained_variance   | 0.309      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0924    |
|    n_updates            | 60         |
|    policy_gradient_loss | -0.0742    |
|    value_loss           | 0.0149     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.6e+03     |
|    ep_rew_mean          | -969        |
| time/                   |             |
|    fps                  | 14          |
|    iterations           | 3           |
|    time_elapsed         | 435         |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.071664676 |
|    clip_fraction        | 0.512       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.13       |
|    explained_variance   | 0.376       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0877     |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.0816     |
|    value_loss           | 0.047       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 4.6e+03    |
|    ep_rew_mean          | -969       |
| time/                   |            |
|    fps                  | 12         |
|    iterations           | 4          |
|    time_elapsed         | 652        |
|    total_timesteps      | 18432      |
| train/                  |            |
|    approx_kl            | 0.07126838 |
|    clip_fraction        | 0.528      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.14      |
|    explained_variance   | 0.287      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.112     |
|    n_updates            | 80         |
|    policy_gradient_loss | -0.0868    |
|    value_loss           | 0.0335     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 4.6e+03     |
|    ep_rew_mean          | -969        |
| time/                   |             |
|    fps                  | 12          |
|    iterations           | 5           |
|    time_elapsed         | 836         |
|    total_timesteps      | 20480       |
| train/                  |             |
|    approx_kl            | 0.047446005 |
|    clip_fraction        | 0.417       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.13       |
|    explained_variance   | 0.207       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0835     |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.0601     |
|    value_loss           | 0.0328      |
-----------------------------------------
On iteration:  2
Logging to logs/test_run4/PPO_0
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 4.6e+03  |
|    ep_rew_mean     | -969     |
| time/              |          |
|    fps             | 22       |
|    iterations      | 1        |
|    time_elapsed    | 89       |
|    total_timesteps | 22528    |
---------------------------------
RESETTING ENVIRONMENT
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 7.9e+03     |
|    ep_rew_mean          | -926        |
| time/                   |             |
|    fps                  | 19          |
|    iterations           | 2           |
|    time_elapsed         | 209         |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.047977977 |
|    clip_fraction        | 0.371       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.1        |
|    explained_variance   | -0.000387   |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0737     |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.0697     |
|    value_loss           | 0.0608      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 7.9e+03     |
|    ep_rew_mean          | -926        |
| time/                   |             |
|    fps                  | 17          |
|    iterations           | 3           |
|    time_elapsed         | 359         |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.035997815 |
|    clip_fraction        | 0.318       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.15       |
|    explained_variance   | 0.0277      |
|    learning_rate        | 0.0003      |
|    loss                 | 36          |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.0144     |
|    value_loss           | 3.82e+03    |
-----------------------------------------
RESETTING ENVIRONMENT
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 7.15e+03   |
|    ep_rew_mean          | -936       |
| time/                   |            |
|    fps                  | 15         |
|    iterations           | 4          |
|    time_elapsed         | 530        |
|    total_timesteps      | 28672      |
| train/                  |            |
|    approx_kl            | 0.12268996 |
|    clip_fraction        | 0.663      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.97      |
|    explained_variance   | 0.712      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.145     |
|    n_updates            | 130        |
|    policy_gradient_loss | -0.0993    |
|    value_loss           | 0.0158     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 7.15e+03   |
|    ep_rew_mean          | -936       |
| time/                   |            |
|    fps                  | 15         |
|    iterations           | 5          |
|    time_elapsed         | 648        |
|    total_timesteps      | 30720      |
| train/                  |            |
|    approx_kl            | 0.03643587 |
|    clip_fraction        | 0.324      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.05      |
|    explained_variance   | 0.00192    |
|    learning_rate        | 0.0003     |
|    loss                 | 178        |
|    n_updates            | 140        |
|    policy_gradient_loss | -0.0163    |
|    value_loss           | 3.69e+03   |
----------------------------------------
On iteration:  3
Logging to logs/test_run4/PPO_0
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 7.15e+03 |
|    ep_rew_mean     | -936     |
| time/              |          |
|    fps             | 14       |
|    iterations      | 1        |
|    time_elapsed    | 140      |
|    total_timesteps | 32768    |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 7.15e+03  |
|    ep_rew_mean          | -936      |
| time/                   |           |
|    fps                  | 13        |
|    iterations           | 2         |
|    time_elapsed         | 292       |
|    total_timesteps      | 34816     |
| train/                  |           |
|    approx_kl            | 0.0786562 |
|    clip_fraction        | 0.518     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.96     |
|    explained_variance   | 0.373     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.105    |
|    n_updates            | 160       |
|    policy_gradient_loss | -0.0742   |
|    value_loss           | 0.0415    |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 7.15e+03    |
|    ep_rew_mean          | -936        |
| time/                   |             |
|    fps                  | 13          |
|    iterations           | 3           |
|    time_elapsed         | 459         |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 0.110677004 |
|    clip_fraction        | 0.604       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.01       |
|    explained_variance   | 0.325       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.124      |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.0923     |
|    value_loss           | 0.0466      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 7.15e+03   |
|    ep_rew_mean          | -936       |
| time/                   |            |
|    fps                  | 13         |
|    iterations           | 4          |
|    time_elapsed         | 627        |
|    total_timesteps      | 38912      |
| train/                  |            |
|    approx_kl            | 0.11117281 |
|    clip_fraction        | 0.562      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.96      |
|    explained_variance   | -0.0492    |
|    learning_rate        | 0.0003     |
|    loss                 | -0.116     |
|    n_updates            | 180        |
|    policy_gradient_loss | -0.0822    |
|    value_loss           | 0.116      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 7.15e+03  |
|    ep_rew_mean          | -936      |
| time/                   |           |
|    fps                  | 13        |
|    iterations           | 5         |
|    time_elapsed         | 765       |
|    total_timesteps      | 40960     |
| train/                  |           |
|    approx_kl            | 0.1335243 |
|    clip_fraction        | 0.566     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.92     |
|    explained_variance   | -0.027    |
|    learning_rate        | 0.0003    |
|    loss                 | -0.14     |
|    n_updates            | 190       |
|    policy_gradient_loss | -0.0947   |
|    value_loss           | 0.144     |
---------------------------------------
On iteration:  4
Logging to logs/test_run4/PPO_0
RESETTING ENVIRONMENT
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 8.26e+03 |
|    ep_rew_mean     | -899     |
| time/              |          |
|    fps             | 21       |
|    iterations      | 1        |
|    time_elapsed    | 94       |
|    total_timesteps | 43008    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 8.26e+03    |
|    ep_rew_mean          | -899        |
| time/                   |             |
|    fps                  | 15          |
|    iterations           | 2           |
|    time_elapsed         | 270         |
|    total_timesteps      | 45056       |
| train/                  |             |
|    approx_kl            | 0.018248398 |
|    clip_fraction        | 0.148       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.95       |
|    explained_variance   | 0.122       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.19e+03    |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.0184     |
|    value_loss           | 3.7e+03     |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 8.26e+03   |
|    ep_rew_mean          | -899       |
| time/                   |            |
|    fps                  | 14         |
|    iterations           | 3          |
|    time_elapsed         | 428        |
|    total_timesteps      | 47104      |
| train/                  |            |
|    approx_kl            | 0.08454761 |
|    clip_fraction        | 0.491      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.6       |
|    explained_variance   | 0.516      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.108     |
|    n_updates            | 220        |
|    policy_gradient_loss | -0.0669    |
|    value_loss           | 0.0127     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 8.26e+03   |
|    ep_rew_mean          | -899       |
| time/                   |            |
|    fps                  | 13         |
|    iterations           | 4          |
|    time_elapsed         | 599        |
|    total_timesteps      | 49152      |
| train/                  |            |
|    approx_kl            | 0.06856237 |
|    clip_fraction        | 0.448      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.68      |
|    explained_variance   | 0.474      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0566    |
|    n_updates            | 230        |
|    policy_gradient_loss | -0.0668    |
|    value_loss           | 0.02       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 8.26e+03    |
|    ep_rew_mean          | -899        |
| time/                   |             |
|    fps                  | 13          |
|    iterations           | 5           |
|    time_elapsed         | 783         |
|    total_timesteps      | 51200       |
| train/                  |             |
|    approx_kl            | 0.062055398 |
|    clip_fraction        | 0.41        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.63       |
|    explained_variance   | 0.415       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.118      |
|    n_updates            | 240         |
|    policy_gradient_loss | -0.0612     |
|    value_loss           | 0.0461      |
-----------------------------------------
On iteration:  5
Logging to logs/test_run4/PPO_0
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 8.26e+03 |
|    ep_rew_mean     | -899     |
| time/              |          |
|    fps             | 19       |
|    iterations      | 1        |
|    time_elapsed    | 106      |
|    total_timesteps | 53248    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 8.26e+03    |
|    ep_rew_mean          | -899        |
| time/                   |             |
|    fps                  | 17          |
|    iterations           | 2           |
|    time_elapsed         | 230         |
|    total_timesteps      | 55296       |
| train/                  |             |
|    approx_kl            | 0.048392992 |
|    clip_fraction        | 0.441       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.8        |
|    explained_variance   | 0.282       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.072      |
|    n_updates            | 260         |
|    policy_gradient_loss | -0.0509     |
|    value_loss           | 0.0761      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 8.26e+03    |
|    ep_rew_mean          | -899        |
| time/                   |             |
|    fps                  | 17          |
|    iterations           | 3           |
|    time_elapsed         | 356         |
|    total_timesteps      | 57344       |
| train/                  |             |
|    approx_kl            | 0.052928623 |
|    clip_fraction        | 0.424       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.87       |
|    explained_variance   | 0.56        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0716     |
|    n_updates            | 270         |
|    policy_gradient_loss | -0.0665     |
|    value_loss           | 0.0441      |
-----------------------------------------
RESETTING ENVIRONMENT
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 9.86e+03    |
|    ep_rew_mean          | -885        |
| time/                   |             |
|    fps                  | 16          |
|    iterations           | 4           |
|    time_elapsed         | 495         |
|    total_timesteps      | 59392       |
| train/                  |             |
|    approx_kl            | 0.058771104 |
|    clip_fraction        | 0.386       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.89       |
|    explained_variance   | 0.196       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0437     |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.0511     |
|    value_loss           | 0.112       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 9.86e+03    |
|    ep_rew_mean          | -885        |
| time/                   |             |
|    fps                  | 16          |
|    iterations           | 5           |
|    time_elapsed         | 604         |
|    total_timesteps      | 61440       |
| train/                  |             |
|    approx_kl            | 0.016581347 |
|    clip_fraction        | 0.154       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.99       |
|    explained_variance   | 0.178       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.08e+04    |
|    n_updates            | 290         |
|    policy_gradient_loss | -0.0162     |
|    value_loss           | 3.64e+03    |
-----------------------------------------
On iteration:  6
Logging to logs/test_run4/PPO_0
RESETTING ENVIRONMENT
Traceback (most recent call last):
  File "C:\Users\yerke\OneDrive - Bob Jones University\Year 4 S1\CpS 499\MyAi\train.py", line 45, in <module>
    model.learn(total_timesteps=TIMESTEPS, reset_num_timesteps=False, tb_log_name=f"PPO")
  File "C:\Users\yerke\AppData\Local\Programs\Python\Python310\lib\site-packages\stable_baselines3\ppo\ppo.py", line 304, in learn
    return super(PPO, self).learn(
  File "C:\Users\yerke\AppData\Local\Programs\Python\Python310\lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 250, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
  File "C:\Users\yerke\AppData\Local\Programs\Python\Python310\lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 178, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
  File "C:\Users\yerke\AppData\Local\Programs\Python\Python310\lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 162, in step
    return self.step_wait()
  File "C:\Users\yerke\AppData\Local\Programs\Python\Python310\lib\site-packages\stable_baselines3\common\vec_env\vec_transpose.py", line 95, in step_wait
    observations, rewards, dones, infos = self.venv.step_wait()
  File "C:\Users\yerke\AppData\Local\Programs\Python\Python310\lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 43, in step_wait
    obs, self.buf_rews[env_idx], self.buf_dones[env_idx], self.buf_infos[env_idx] = self.envs[env_idx].step(
  File "C:\Users\yerke\AppData\Local\Programs\Python\Python310\lib\site-packages\stable_baselines3\common\monitor.py", line 90, in step
    observation, reward, done, info = self.env.step(action)
  File "C:\Users\yerke\OneDrive - Bob Jones University\Year 4 S1\CpS 499\MyAi\sc2env.py", line 26, in step
    with open('state_rwd_action.pkl', 'rb') as f:
KeyboardInterrupt